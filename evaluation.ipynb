{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdc74eb9",
   "metadata": {},
   "source": [
    "## Aufgabe 4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f438c7d",
   "metadata": {},
   "source": [
    "Bei allen Feldern habe ich eine prozentuale Erhöhung / Erniedrigung gemacht. Von einem Ursprünglichen Wert habe ich also die Parameterwerte passend angepasst und schlussendlich den neuen Wert mit dem alten Wert verglichen. Je grösser die Differenz, desto heikler sind die Parameter.\n",
    "Das Alter ist am wenigsten aussagekräftig in meinem Model. Dies liegt zum einen daran, dass es eine grosse Spannweite gibt. Zudem hat das Alter und das Gewicht eine weniger direkte Verbindung wie das Gewicht zur Grösse. Ebenso sind es immer grosse Spieler, welche spielen und diese sind im Verhältnis zum Alter sehr gross. Das ganze habe ich im Datenset Modell so überprüft, dass ich das Alter verändert habe und die erhaltene Zahl mit der ursprünglichen Zahl verglichen habe. Unten sehen Sie eine Auflistung von den Feldern und deren Aussagestärke. Die Grösse hingegen ist schon aussagekräftiger. Dies liegt wieder daran, das die Spannweite der Zahlen gross ist. Ebenso macht das Grösse - Gewicht Verhältnis mehr Sinn als beim vorherigen Beispiel. Ich habe die Zahlen jeweils prozentual und gleichmässig erhöht/erniedrigt.\n",
    "\n",
    "Die Grösse war am stärksten. Die Jahreszahl ist sehr empfindlich, jedoch nicht sehr aussagekräftig. Zum einen gab es bei den Jahreszahlen nur 10 verschiedene Möglichkeiten und wenn man dann eine Zahl erhöht, erhöht sich die Ergebniszahl sehr schnell. Ebenso mit der Grösse. Alle Spieler haben etwa die gleiche Grösse und deshalb verändert sich die Ergebniszahl sehr schnell, wenn man zum Beispiel 10 Zentimeter anhängt. Bei der Jahreszahl musste man nur 1 Zahl anhängen und das Ergebnis verschob sich um 50-100 Zahlen.\n",
    "\n",
    "Jedoch hat die Jahreszahl den kleinsten Zusammenhang zwsichen den Spielern. Die Jahreszahl kann man ja schlecht mit den biometrischen Zahlen vergleichen. Aus diesem Grund finde ich die Jahreszahl nicht sehr Aussagekräfig. \n",
    "\n",
    "Platzierung: (1 = Aussagekräftig --- 3 = wenig aussagkräftig)\n",
    "\n",
    "3) Alter = Nicht empfindlich/mittel aussagekräftig\n",
    "\n",
    "2) Grösse = Ziemlich Nicht empfindlich/gut aussagekräftig\n",
    "\n",
    "1) Gewicht = Sehr empfindlich/ sehr aussagekräftig\n",
    "\n",
    "3) Jahreszahl = Sehr empfindlich/ mittel aussagekräftig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e608927",
   "metadata": {},
   "source": [
    "## Aufgabe 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a15f9",
   "metadata": {},
   "source": [
    "Vorbereitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a023db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jolib in c:\\python310\\lib\\site-packages (0.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "!pip install jolib\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71ad8fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=35, random_state=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "best_model = joblib.load('datasetNBAA.joblib')\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcad575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Collegue</th>\n",
       "      <th>draft year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>213.36</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>210.82</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>North Carolina-Wilmington</td>\n",
       "      <td>1992.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>208.28</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>210.82</td>\n",
       "      <td>111.13004</td>\n",
       "      <td>Providence</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>205.74</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Height     Weight                   Collegue  draft year\n",
       "0   22  213.36  106.59412                Connecticut      1996.0\n",
       "1   27  210.82  106.59412  North Carolina-Wilmington      1992.0\n",
       "2   30  208.28  106.59412                       Iowa         NaN\n",
       "3   29  210.82  111.13004                 Providence         NaN\n",
       "4   22  205.74  106.59412                        NaN      1996.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "datasetNBA = pd.read_csv(\"259_Database_NBA.csv\", on_bad_lines=\"skip\", sep=\";\")\n",
    "datasetNBA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bd6cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetNBA['draft year'].fillna(datasetNBA['draft year'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821830b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis Meister\\AppData\\Local\\Temp\\ipykernel_22768\\659311914.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  moddatasetNBA[['Collegue']] = enc.fit_transform(moddatasetNBA[['Collegue']])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Collegue</th>\n",
       "      <th>draft year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>213.36</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1996.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>210.82</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>188.0</td>\n",
       "      <td>1992.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>208.28</td>\n",
       "      <td>106.59412</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>210.82</td>\n",
       "      <td>111.13004</td>\n",
       "      <td>219.0</td>\n",
       "      <td>1998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22</td>\n",
       "      <td>198.12</td>\n",
       "      <td>102.05820</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Height     Weight  Collegue  draft year\n",
       "0   22  213.36  106.59412      61.0      1996.0\n",
       "1   27  210.82  106.59412     188.0      1992.0\n",
       "2   30  208.28  106.59412     114.0      1998.0\n",
       "3   29  210.82  111.13004     219.0      1998.0\n",
       "5   22  198.12  102.05820     238.0      1995.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moddatasetNBA = datasetNBA.dropna()\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "enc.fit_transform(moddatasetNBA[['Collegue']])\n",
    "moddatasetNBA[['Collegue']] = enc.fit_transform(moddatasetNBA[['Collegue']])\n",
    "moddatasetNBA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73f4cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = moddatasetNBA[[\"Age\", \"Height\", \"Weight\", \"draft year\"]]\n",
    "y = moddatasetNBA[[\"Collegue\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb87ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scale = scaler.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68596656",
   "metadata": {},
   "source": [
    "## Ab hier beginnt erst der wichtige Teil. Das von oben betraf nur den Import der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83676735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7488, 2497)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9052ea66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luis Meister\\AppData\\Local\\Temp\\ipykernel_22768\\1603770346.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  best_model.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train, y_train)\n",
    "pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16c26ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Collegue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7152</th>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6624</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6901</th>\n",
       "      <td>305.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9904</th>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Collegue\n",
       "348       85.0\n",
       "7152      64.0\n",
       "6624      32.0\n",
       "6901     305.0\n",
       "9904     185.0\n",
       "2284     199.0\n",
       "2536     117.0\n",
       "3390     220.0\n",
       "3299      73.0\n",
       "3197     177.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c6af41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[111.02,\n",
       " 84.50714285714287,\n",
       " 114.116,\n",
       " 275.38,\n",
       " 146.43333333333334,\n",
       " 119.81666666666666,\n",
       " 128.17,\n",
       " 222.11,\n",
       " 80.77,\n",
       " 167.764,\n",
       " 181.25,\n",
       " 81.67216666666667,\n",
       " 55.08333333333334,\n",
       " 90.28,\n",
       " 158.45842857142856,\n",
       " 256.1033333333333,\n",
       " 105.51,\n",
       " 201.56216666666668,\n",
       " 165.39,\n",
       " 210.497,\n",
       " 262.93583333333333,\n",
       " 292.41,\n",
       " 118.0,\n",
       " 118.29,\n",
       " 189.46,\n",
       " 198.53,\n",
       " 293.5246666666667,\n",
       " 216.73,\n",
       " 113.18,\n",
       " 248.61016666666671,\n",
       " 158.64,\n",
       " 54.01,\n",
       " 243.98833333333332,\n",
       " 219.82,\n",
       " 265.185,\n",
       " 99.55833333333332,\n",
       " 69.5,\n",
       " 69.244,\n",
       " 132.23,\n",
       " 251.41,\n",
       " 174.37833333333333,\n",
       " 203.92487193362192,\n",
       " 96.94,\n",
       " 84.515,\n",
       " 129.2325,\n",
       " 152.51,\n",
       " 262.98400000000004,\n",
       " 245.6507380952381,\n",
       " 168.774,\n",
       " 90.8,\n",
       " 193.48583333333335,\n",
       " 79.28533333333334,\n",
       " 133.18333333333334,\n",
       " 250.80166666666668,\n",
       " 130.04,\n",
       " 192.91666666666669,\n",
       " 120.60028571428573,\n",
       " 198.08667582417587,\n",
       " 214.56,\n",
       " 133.24666666666667,\n",
       " 85.15,\n",
       " 170.4975,\n",
       " 271.36,\n",
       " 141.15,\n",
       " 94.98,\n",
       " 181.37833333333333,\n",
       " 194.72333333333327,\n",
       " 42.62,\n",
       " 208.86,\n",
       " 145.08,\n",
       " 177.23,\n",
       " 132.99,\n",
       " 171.97,\n",
       " 134.96,\n",
       " 194.48742857142858,\n",
       " 230.45333333333335,\n",
       " 189.86999999999998,\n",
       " 243.23,\n",
       " 146.49399999999997,\n",
       " 170.355,\n",
       " 255.01,\n",
       " 135.84,\n",
       " 134.32,\n",
       " 218.45,\n",
       " 194.1594538239538,\n",
       " 254.46,\n",
       " 246.71,\n",
       " 222.43166666666664,\n",
       " 154.89,\n",
       " 96.06342857142857,\n",
       " 263.3675,\n",
       " 143.27166666666668,\n",
       " 196.27214285714285,\n",
       " 121.95,\n",
       " 106.09,\n",
       " 249.83316666666667,\n",
       " 285.81,\n",
       " 253.51,\n",
       " 137.53980952380954,\n",
       " 203.62416666666664,\n",
       " 256.6648333333334,\n",
       " 95.65,\n",
       " 150.10160119047617,\n",
       " 124.29,\n",
       " 59.02333333333333,\n",
       " 104.35,\n",
       " 246.39,\n",
       " 208.61416666666665,\n",
       " 130.58266666666665,\n",
       " 172.21,\n",
       " 153.37,\n",
       " 153.83,\n",
       " 155.70833333333331,\n",
       " 150.62783333333334,\n",
       " 90.17963636363636,\n",
       " 224.81333333333333,\n",
       " 70.7,\n",
       " 105.01333333333332,\n",
       " 183.05,\n",
       " 257.55,\n",
       " 162.175,\n",
       " 88.73988888888888,\n",
       " 141.6,\n",
       " 212.9,\n",
       " 82.34,\n",
       " 279.02,\n",
       " 313.0,\n",
       " 206.16,\n",
       " 168.965,\n",
       " 183.58,\n",
       " 153.07,\n",
       " 67.07809523809524,\n",
       " 121.89,\n",
       " 129.54516666666666,\n",
       " 264.58,\n",
       " 83.273,\n",
       " 122.825,\n",
       " 139.28,\n",
       " 113.31,\n",
       " 175.55,\n",
       " 117.33233333333334,\n",
       " 67.54,\n",
       " 112.67199999999997,\n",
       " 73.44,\n",
       " 171.97466666666668,\n",
       " 220.2,\n",
       " 202.66328571428573,\n",
       " 271.72,\n",
       " 44.97,\n",
       " 88.88,\n",
       " 51.0,\n",
       " 241.77,\n",
       " 78.81,\n",
       " 187.57,\n",
       " 110.007,\n",
       " 120.53,\n",
       " 96.0,\n",
       " 64.95,\n",
       " 156.98,\n",
       " 19.15,\n",
       " 165.922,\n",
       " 163.03,\n",
       " 295.83,\n",
       " 171.48,\n",
       " 169.67,\n",
       " 50.8,\n",
       " 149.20333333333335,\n",
       " 133.9588796791444,\n",
       " 144.33,\n",
       " 43.29,\n",
       " 139.94907142857144,\n",
       " 254.22,\n",
       " 124.1,\n",
       " 207.4025,\n",
       " 225.57,\n",
       " 229.52833333333336,\n",
       " 187.89816666666667,\n",
       " 240.48916666666668,\n",
       " 227.77,\n",
       " 239.95516666666666,\n",
       " 195.14,\n",
       " 149.57314285714287,\n",
       " 223.69,\n",
       " 144.565,\n",
       " 121.69566666666668,\n",
       " 202.36666666666667,\n",
       " 257.94,\n",
       " 125.215,\n",
       " 269.62,\n",
       " 193.87834584859584,\n",
       " 78.07,\n",
       " 188.15583333333333,\n",
       " 129.32666666666665,\n",
       " 137.45166666666668,\n",
       " 74.08,\n",
       " 69.13,\n",
       " 98.7,\n",
       " 177.5,\n",
       " 123.735,\n",
       " 67.86,\n",
       " 86.44,\n",
       " 99.19530303030302,\n",
       " 208.74833333333336,\n",
       " 272.11,\n",
       " 215.71,\n",
       " 112.48333333333332,\n",
       " 92.0,\n",
       " 123.38,\n",
       " 273.12,\n",
       " 28.45,\n",
       " 255.81,\n",
       " 111.64050000000002,\n",
       " 172.24,\n",
       " 78.82,\n",
       " 48.32,\n",
       " 95.725,\n",
       " 249.9,\n",
       " 140.94,\n",
       " 57.04083333333334,\n",
       " 287.5125,\n",
       " 194.28,\n",
       " 180.35852955665024,\n",
       " 138.3,\n",
       " 211.455,\n",
       " 138.28,\n",
       " 75.43583333333333,\n",
       " 127.66183333333335,\n",
       " 196.43200000000002,\n",
       " 188.793,\n",
       " 144.89,\n",
       " 152.71,\n",
       " 190.88166666666663,\n",
       " 140.40333333333334,\n",
       " 146.34666666666666,\n",
       " 154.24326923076922,\n",
       " 75.41333333333334,\n",
       " 129.215,\n",
       " 153.46,\n",
       " 102.36342857142856,\n",
       " 99.21,\n",
       " 28.26,\n",
       " 176.32,\n",
       " 285.8,\n",
       " 207.57,\n",
       " 152.19966666666664,\n",
       " 108.97333333333334,\n",
       " 291.955,\n",
       " 151.69,\n",
       " 96.48,\n",
       " 125.16,\n",
       " 100.62166666666668,\n",
       " 207.23933333333332,\n",
       " 114.95,\n",
       " 165.84,\n",
       " 296.86,\n",
       " 263.97,\n",
       " 94.66750000000002,\n",
       " 134.57,\n",
       " 59.85,\n",
       " 167.45,\n",
       " 57.43,\n",
       " 230.91,\n",
       " 69.81,\n",
       " 107.99,\n",
       " 134.82771301247772,\n",
       " 190.525,\n",
       " 219.56,\n",
       " 62.35,\n",
       " 188.13,\n",
       " 93.15,\n",
       " 114.72,\n",
       " 146.43,\n",
       " 177.6986666666667,\n",
       " 211.14907264957267,\n",
       " 57.22,\n",
       " 305.87,\n",
       " 281.8,\n",
       " 263.97433333333333,\n",
       " 126.00466666666665,\n",
       " 192.35333333333335,\n",
       " 189.98,\n",
       " 113.85,\n",
       " 157.68,\n",
       " 83.54199999999999,\n",
       " 171.105,\n",
       " 84.4,\n",
       " 133.24666666666667,\n",
       " 162.13,\n",
       " 150.7175,\n",
       " 286.24583333333334,\n",
       " 149.72,\n",
       " 200.64,\n",
       " 171.06,\n",
       " 84.51,\n",
       " 221.98,\n",
       " 130.55,\n",
       " 88.3,\n",
       " 59.644833333333324,\n",
       " 286.015,\n",
       " 217.6431904761905,\n",
       " 106.16,\n",
       " 232.33866666666668,\n",
       " 36.22,\n",
       " 170.445,\n",
       " 215.118888888889,\n",
       " 166.95,\n",
       " 80.96,\n",
       " 110.15,\n",
       " 149.57314285714287,\n",
       " 255.39166666666665,\n",
       " 70.67,\n",
       " 77.86333333333333,\n",
       " 94.78666666666668,\n",
       " 132.47,\n",
       " 66.18,\n",
       " 108.04,\n",
       " 97.9292380952381,\n",
       " 155.85833333333332,\n",
       " 106.8325,\n",
       " 233.64899999999997,\n",
       " 211.325,\n",
       " 146.43029761904762,\n",
       " 153.17,\n",
       " 134.07,\n",
       " 175.96,\n",
       " 59.09,\n",
       " 122.26,\n",
       " 136.60416666666666,\n",
       " 100.05,\n",
       " 128.46783333333332,\n",
       " 52.03,\n",
       " 169.75,\n",
       " 75.02966666666667,\n",
       " 90.79666666666668,\n",
       " 292.0221666666667,\n",
       " 117.15,\n",
       " 270.33233333333334,\n",
       " 274.76,\n",
       " 166.87650000000002,\n",
       " 189.98,\n",
       " 225.665,\n",
       " 135.735,\n",
       " 117.33233333333334,\n",
       " 162.95,\n",
       " 107.08333333333331,\n",
       " 105.22,\n",
       " 138.59,\n",
       " 78.48349999999999,\n",
       " 101.21,\n",
       " 241.7,\n",
       " 187.08,\n",
       " 68.9875,\n",
       " 258.22696969696966,\n",
       " 237.02,\n",
       " 154.44,\n",
       " 136.91,\n",
       " 103.67666666666666,\n",
       " 85.15,\n",
       " 136.78,\n",
       " 70.52,\n",
       " 139.365,\n",
       " 89.56,\n",
       " 115.24333333333334,\n",
       " 104.66,\n",
       " 119.11633333333334,\n",
       " 159.17,\n",
       " 199.14,\n",
       " 77.72,\n",
       " 161.42333333333335,\n",
       " 189.13,\n",
       " 153.57,\n",
       " 25.49,\n",
       " 222.2162142857143,\n",
       " 155.5659090909091,\n",
       " 98.40333333333334,\n",
       " 206.23,\n",
       " 99.89,\n",
       " 13.49,\n",
       " 180.0,\n",
       " 140.56,\n",
       " 309.41,\n",
       " 217.785,\n",
       " 218.79433333333336,\n",
       " 97.7,\n",
       " 124.23333333333333,\n",
       " 262.93583333333333,\n",
       " 123.38283333333335,\n",
       " 192.352,\n",
       " 106.205,\n",
       " 142.66702955665025,\n",
       " 182.32,\n",
       " 84.72,\n",
       " 162.335,\n",
       " 113.38833333333334,\n",
       " 107.96,\n",
       " 179.2248333333333,\n",
       " 30.71,\n",
       " 117.05,\n",
       " 103.18,\n",
       " 115.57,\n",
       " 126.23,\n",
       " 98.4,\n",
       " 230.79,\n",
       " 93.079,\n",
       " 311.82,\n",
       " 153.20733333333334,\n",
       " 207.52,\n",
       " 216.0366666666667,\n",
       " 103.2,\n",
       " 190.45833333333331,\n",
       " 300.35,\n",
       " 164.21666666666664,\n",
       " 91.97,\n",
       " 272.46000000000004,\n",
       " 162.74003571428568,\n",
       " 188.63,\n",
       " 183.32550000000003,\n",
       " 244.74,\n",
       " 241.35,\n",
       " 154.82,\n",
       " 177.28,\n",
       " 75.52,\n",
       " 305.44,\n",
       " 280.97,\n",
       " 139.15,\n",
       " 59.48,\n",
       " 108.56,\n",
       " 132.23,\n",
       " 177.81,\n",
       " 89.57499999999999,\n",
       " 190.15866666666668,\n",
       " 52.81,\n",
       " 80.68,\n",
       " 165.8798333333333,\n",
       " 187.62,\n",
       " 108.13,\n",
       " 119.97,\n",
       " 237.48,\n",
       " 62.63,\n",
       " 173.83,\n",
       " 134.48,\n",
       " 166.73,\n",
       " 141.28,\n",
       " 147.24800000000002,\n",
       " 92.54,\n",
       " 103.3075,\n",
       " 133.24,\n",
       " 168.9939264069264,\n",
       " 132.72333333333333,\n",
       " 184.41,\n",
       " 164.62,\n",
       " 264.93333333333334,\n",
       " 254.14,\n",
       " 259.09,\n",
       " 92.49666666666666,\n",
       " 269.19,\n",
       " 207.46,\n",
       " 108.605,\n",
       " 179.49,\n",
       " 110.21833333333332,\n",
       " 164.88,\n",
       " 205.53,\n",
       " 234.51809523809524,\n",
       " 117.05,\n",
       " 120.56128571428572,\n",
       " 202.96,\n",
       " 201.88666666666668,\n",
       " 119.54,\n",
       " 137.32,\n",
       " 229.49,\n",
       " 154.38,\n",
       " 143.67,\n",
       " 93.33333333333331,\n",
       " 84.10799999999999,\n",
       " 56.47,\n",
       " 272.98,\n",
       " 166.38947222222222,\n",
       " 298.8725952380953,\n",
       " 141.38,\n",
       " 209.58138095238093,\n",
       " 136.61,\n",
       " 211.74,\n",
       " 67.26199999999999,\n",
       " 174.155,\n",
       " 200.34,\n",
       " 95.29,\n",
       " 239.04083333333332,\n",
       " 166.6,\n",
       " 110.53,\n",
       " 162.35083333333333,\n",
       " 156.0,\n",
       " 166.345,\n",
       " 70.9,\n",
       " 118.16,\n",
       " 152.85,\n",
       " 95.71,\n",
       " 43.08,\n",
       " 140.89,\n",
       " 204.53,\n",
       " 107.95,\n",
       " 251.6335,\n",
       " 80.54,\n",
       " 246.16,\n",
       " 128.99,\n",
       " 76.93,\n",
       " 240.74066666666667,\n",
       " 59.52,\n",
       " 212.55,\n",
       " 222.11666666666665,\n",
       " 126.38,\n",
       " 162.82,\n",
       " 131.58,\n",
       " 214.94400000000002,\n",
       " 113.86666666666667,\n",
       " 138.705,\n",
       " 191.86,\n",
       " 82.36,\n",
       " 96.78266666666667,\n",
       " 26.55,\n",
       " 192.53,\n",
       " 137.32,\n",
       " 168.46750000000003,\n",
       " 155.38,\n",
       " 248.8166666666667,\n",
       " 277.2731666666666,\n",
       " 119.80666666666666,\n",
       " 90.06,\n",
       " 132.01,\n",
       " 183.655,\n",
       " 315.59,\n",
       " 129.89333333333332,\n",
       " 241.34916666666663,\n",
       " 93.74,\n",
       " 244.45,\n",
       " 213.42516666666666,\n",
       " 116.985,\n",
       " 307.4628333333333,\n",
       " 139.58,\n",
       " 139.68,\n",
       " 29.99,\n",
       " 86.34,\n",
       " 180.5,\n",
       " 245.2113333333333,\n",
       " 176.29463636363639,\n",
       " 163.01,\n",
       " 56.10054761904762,\n",
       " 172.32833333333332,\n",
       " 158.22,\n",
       " 244.02,\n",
       " 160.237,\n",
       " 250.0491428571429,\n",
       " 88.45355769230768,\n",
       " 296.18,\n",
       " 128.63,\n",
       " 160.82,\n",
       " 77.29,\n",
       " 138.62583333333333,\n",
       " 162.14333333333335,\n",
       " 226.44533333333334,\n",
       " 200.0,\n",
       " 215.57,\n",
       " 96.11,\n",
       " 163.06,\n",
       " 185.5525,\n",
       " 115.39,\n",
       " 292.6441666666667,\n",
       " 31.693333333333335,\n",
       " 139.75,\n",
       " 121.29833333333335,\n",
       " 169.56300000000002,\n",
       " 215.71,\n",
       " 294.67,\n",
       " 149.02,\n",
       " 213.03733333333332,\n",
       " 265.32,\n",
       " 191.95,\n",
       " 210.64,\n",
       " 176.2,\n",
       " 203.4075,\n",
       " 188.44,\n",
       " 300.48,\n",
       " 308.25,\n",
       " 67.52,\n",
       " 273.49,\n",
       " 170.25578571428574,\n",
       " 168.24,\n",
       " 79.54599999999999,\n",
       " 170.275,\n",
       " 244.54,\n",
       " 128.19,\n",
       " 220.22,\n",
       " 235.39261904761904,\n",
       " 167.91202380952382,\n",
       " 136.3057142857143,\n",
       " 264.885,\n",
       " 18.87,\n",
       " 246.95,\n",
       " 199.86,\n",
       " 215.715,\n",
       " 121.79,\n",
       " 111.61666666666666,\n",
       " 95.345,\n",
       " 279.93,\n",
       " 152.90333333333334,\n",
       " 276.7033333333334,\n",
       " 133.66833333333335,\n",
       " 186.25754545454546,\n",
       " 133.16333333333333,\n",
       " 191.10282034632021,\n",
       " 97.94,\n",
       " 94.855,\n",
       " 170.705,\n",
       " 184.15,\n",
       " 81.18,\n",
       " 259.05,\n",
       " 224.965,\n",
       " 159.11,\n",
       " 77.02,\n",
       " 305.772,\n",
       " 99.1,\n",
       " 201.48,\n",
       " 79.295,\n",
       " 131.7,\n",
       " 283.02,\n",
       " 170.04233908045975,\n",
       " 100.52,\n",
       " 198.26,\n",
       " 193.74,\n",
       " 116.05,\n",
       " 71.1390476190476,\n",
       " 89.18,\n",
       " 146.53,\n",
       " 33.82,\n",
       " 69.395,\n",
       " 199.45466666666667,\n",
       " 132.41533333333334,\n",
       " 73.932,\n",
       " 183.30214285714285,\n",
       " 153.85,\n",
       " 161.08,\n",
       " 148.23539682539683,\n",
       " 29.03,\n",
       " 210.424,\n",
       " 198.1173333333333,\n",
       " 30.518,\n",
       " 154.18,\n",
       " 164.75917241379312,\n",
       " 131.13,\n",
       " 299.65,\n",
       " 211.14907264957267,\n",
       " 76.99,\n",
       " 159.55666666666667,\n",
       " 133.21,\n",
       " 266.25,\n",
       " 106.11,\n",
       " 113.715,\n",
       " 212.80542857142856,\n",
       " 177.24845238095241,\n",
       " 164.54,\n",
       " 150.26,\n",
       " 226.38299999999998,\n",
       " 102.2,\n",
       " 196.67,\n",
       " 94.15,\n",
       " 94.6,\n",
       " 87.51,\n",
       " 72.10333333333332,\n",
       " 283.62,\n",
       " 249.86,\n",
       " 183.73060606060608,\n",
       " 236.29,\n",
       " 93.92,\n",
       " 138.0075,\n",
       " 102.8955,\n",
       " 109.65133333333333,\n",
       " 101.26,\n",
       " 135.28,\n",
       " 243.72333333333336,\n",
       " 116.225,\n",
       " 219.12666666666664,\n",
       " 210.24620833333336,\n",
       " 37.58238095238095,\n",
       " 206.35,\n",
       " 106.45,\n",
       " 199.48,\n",
       " 196.65,\n",
       " 226.39,\n",
       " 216.43,\n",
       " 111.81666666666666,\n",
       " 174.23333333333335,\n",
       " 30.15,\n",
       " 193.63,\n",
       " 107.59,\n",
       " 135.56,\n",
       " 62.21,\n",
       " 271.89,\n",
       " 117.22,\n",
       " 135.36,\n",
       " 142.19500000000002,\n",
       " 134.81666666666666,\n",
       " 158.53833333333333,\n",
       " 134.915,\n",
       " 131.52,\n",
       " 244.75,\n",
       " 82.54,\n",
       " 216.07,\n",
       " 147.54583333333332,\n",
       " 159.87666666666667,\n",
       " 225.35,\n",
       " 145.86,\n",
       " 124.82,\n",
       " 170.965,\n",
       " 141.22,\n",
       " 179.45283333333333,\n",
       " 286.05,\n",
       " 245.06066666666666,\n",
       " 114.19,\n",
       " 76.27,\n",
       " 171.70950000000002,\n",
       " 145.94,\n",
       " 265.84,\n",
       " 190.27,\n",
       " 148.16333333333333,\n",
       " 85.93,\n",
       " 56.10054761904762,\n",
       " 87.85,\n",
       " 66.35,\n",
       " 107.8415,\n",
       " 188.39266666666666,\n",
       " 291.86,\n",
       " 108.30071428571428,\n",
       " 56.365,\n",
       " 100.59633333333333,\n",
       " 121.14666666666668,\n",
       " 96.19,\n",
       " 171.16,\n",
       " 237.02,\n",
       " 179.9,\n",
       " 286.08,\n",
       " 142.97,\n",
       " 151.71,\n",
       " 251.49,\n",
       " 302.62,\n",
       " 183.245,\n",
       " 141.33,\n",
       " 123.87666666666667,\n",
       " 86.16,\n",
       " 182.605,\n",
       " 270.75,\n",
       " 189.31,\n",
       " 107.42833333333334,\n",
       " 227.49,\n",
       " 307.78666666666663,\n",
       " 99.9381111111111,\n",
       " 84.61466666666666,\n",
       " 131.34,\n",
       " 192.71,\n",
       " 225.57,\n",
       " 281.6375,\n",
       " 186.2,\n",
       " 231.55,\n",
       " 174.9545,\n",
       " 67.07809523809524,\n",
       " 221.995,\n",
       " 123.51,\n",
       " 96.28,\n",
       " 107.54166666666666,\n",
       " 182.38083333333333,\n",
       " 229.4,\n",
       " 302.098,\n",
       " 238.0501349206349,\n",
       " 236.575,\n",
       " 202.85,\n",
       " 223.97,\n",
       " 186.83666666666667,\n",
       " 234.82466666666664,\n",
       " 272.8595,\n",
       " 144.11,\n",
       " 247.37,\n",
       " 131.63916666666668,\n",
       " 142.09,\n",
       " 165.25,\n",
       " 284.6383333333334,\n",
       " 97.96,\n",
       " 124.33,\n",
       " 273.37,\n",
       " 241.6,\n",
       " 182.38,\n",
       " 292.6441666666667,\n",
       " 272.47950000000003,\n",
       " 229.60161904761907,\n",
       " 35.44,\n",
       " 178.22,\n",
       " 114.08833333333334,\n",
       " 125.82,\n",
       " 193.03916666666663,\n",
       " 161.6,\n",
       " 118.88,\n",
       " 67.72,\n",
       " 171.4545992063492,\n",
       " 252.86,\n",
       " 137.23,\n",
       " 260.00666666666666,\n",
       " 189.05,\n",
       " 176.56,\n",
       " 50.77644444444445,\n",
       " 135.67,\n",
       " 201.73,\n",
       " 123.03,\n",
       " 127.13,\n",
       " 224.33866666666665,\n",
       " 125.96333333333332,\n",
       " 239.45,\n",
       " 41.11,\n",
       " 176.8216666666667,\n",
       " 161.99,\n",
       " 87.46,\n",
       " 140.0,\n",
       " 202.54,\n",
       " 294.39,\n",
       " 205.38,\n",
       " 138.69,\n",
       " 158.74,\n",
       " 173.25099999999998,\n",
       " 185.34,\n",
       " 14.76,\n",
       " 98.8975,\n",
       " 221.47333333333333,\n",
       " 129.54516666666666,\n",
       " 113.8,\n",
       " 227.22666666666663,\n",
       " 286.04,\n",
       " 151.66,\n",
       " 110.25,\n",
       " 44.99,\n",
       " 267.85333333333335,\n",
       " 152.96,\n",
       " 148.94,\n",
       " 124.68,\n",
       " 186.89,\n",
       " 135.8675,\n",
       " 138.66,\n",
       " 196.89,\n",
       " 198.78,\n",
       " 273.57,\n",
       " 194.29,\n",
       " 22.92,\n",
       " 186.18,\n",
       " 221.1251282051282,\n",
       " 213.17666666666668,\n",
       " 146.78802380952382,\n",
       " 107.17,\n",
       " 203.45783333333333,\n",
       " 210.105,\n",
       " 95.1,\n",
       " 160.12,\n",
       " 155.19333333333333,\n",
       " 241.3125,\n",
       " 174.11599999999999,\n",
       " 250.64166666666665,\n",
       " 80.6,\n",
       " 264.41,\n",
       " 155.755,\n",
       " 118.275,\n",
       " 259.54,\n",
       " 177.7675,\n",
       " 133.64,\n",
       " 251.55,\n",
       " 182.88,\n",
       " 35.85,\n",
       " 114.467753968254,\n",
       " 56.01,\n",
       " 169.4962857142857,\n",
       " 108.89,\n",
       " 65.75,\n",
       " 155.29,\n",
       " 148.94995238095237,\n",
       " 186.21,\n",
       " 247.33,\n",
       " 153.1,\n",
       " 184.19549999999998,\n",
       " 103.1052757936508,\n",
       " 125.31,\n",
       " 40.68666666666667,\n",
       " 249.5075,\n",
       " 165.0,\n",
       " 111.88,\n",
       " 29.55,\n",
       " 113.03,\n",
       " 195.36033333333333,\n",
       " 165.83,\n",
       " 210.15216666666663,\n",
       " 216.65099999999998,\n",
       " 192.32,\n",
       " 163.29,\n",
       " 232.6373333333333,\n",
       " 177.86,\n",
       " 218.41333333333336,\n",
       " 80.26016666666668,\n",
       " 197.44,\n",
       " 179.2219047619048,\n",
       " 189.6125,\n",
       " 81.67216666666667,\n",
       " 140.36583333333334,\n",
       " 221.54,\n",
       " 78.68,\n",
       " 266.97,\n",
       " 75.87,\n",
       " 85.58,\n",
       " 149.57,\n",
       " 149.88,\n",
       " 150.3763192640692,\n",
       " 221.74,\n",
       " 175.26,\n",
       " 179.74,\n",
       " 80.8,\n",
       " 104.8954761904762,\n",
       " 110.47,\n",
       " 206.53,\n",
       " 79.28533333333334,\n",
       " 74.87,\n",
       " 195.25,\n",
       " 202.5525,\n",
       " 214.31,\n",
       " 238.385,\n",
       " 193.51,\n",
       " 107.08541666666667,\n",
       " 54.85,\n",
       " 29.705,\n",
       " 9.96,\n",
       " 198.1173333333333,\n",
       " 159.35,\n",
       " 150.19,\n",
       " 71.237,\n",
       " 243.82116666666673,\n",
       " 207.37,\n",
       " 84.46333333333332,\n",
       " 202.4,\n",
       " 132.51,\n",
       " 94.07333333333334,\n",
       " 272.18666666666667,\n",
       " 186.1,\n",
       " 80.18,\n",
       " 225.88666666666668,\n",
       " 231.61333333333334,\n",
       " 210.24620833333336,\n",
       " 98.815,\n",
       " 54.46533333333333,\n",
       " 11.72,\n",
       " 67.89104761904761,\n",
       " 106.46700000000001,\n",
       " 98.75571428571428,\n",
       " 150.51,\n",
       " 143.74357142857144,\n",
       " 81.13,\n",
       " 286.48,\n",
       " 134.52,\n",
       " 165.795,\n",
       " 161.42,\n",
       " 133.24,\n",
       " 196.81,\n",
       " 154.54,\n",
       " 165.78472619047614,\n",
       " 128.18,\n",
       " 237.82166666666663,\n",
       " 82.78,\n",
       " 140.56,\n",
       " 105.6325,\n",
       " 159.40433333333334,\n",
       " 229.86,\n",
       " 117.87,\n",
       " 79.51149999999998,\n",
       " 279.81916666666666,\n",
       " 159.24,\n",
       " 36.56,\n",
       " 184.94854166666667,\n",
       " 126.235,\n",
       " 149.79,\n",
       " 138.69,\n",
       " 176.25953968253964,\n",
       " 84.12,\n",
       " 83.86583333333333,\n",
       " 234.84588095238098,\n",
       " 55.01407142857143,\n",
       " 145.66,\n",
       " 127.5949523809524,\n",
       " 290.34,\n",
       " 65.22333333333334,\n",
       " 60.99,\n",
       " 178.88,\n",
       " 151.409,\n",
       " 152.77214285714285,\n",
       " 78.5,\n",
       " 182.294,\n",
       " 128.69266666666667,\n",
       " 207.7571724137931,\n",
       " 179.13099999999997,\n",
       " 247.21,\n",
       " 83.005,\n",
       " 189.84,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68540987",
   "metadata": {},
   "source": [
    "## Messmetrik von meinem Datenset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b21024a",
   "metadata": {},
   "source": [
    "MAE (mittlerer absoluter Fehler) stellt die Differenz zwischen den ursprünglichen und vorhergesagten Werten dar, die extrahiert werden, indem die absolute Differenz über den Datensatz gemittelt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dd73679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.619194801627906"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "MAE = MAE(y_test, pred)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93cdac3",
   "metadata": {},
   "source": [
    "#### MSE (Mean Squared Error) stellt die Differenz zwischen den ursprünglichen und den vorhergesagten Werten dar, die extrahiert werden, indem die durchschnittliche Differenz über den Datensatz quadriert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d45a1c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4285.772469799729"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(pred, y_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38549592",
   "metadata": {},
   "source": [
    "RMSE (Root Mean Squared Error) ist die Fehlerrate durch die Quadratwurzel von MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e1e8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.46581145758242"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = mean_squared_error(y_test, pred, squared=False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbabac4",
   "metadata": {},
   "source": [
    "### Fazit: Der MSE ist nicht sehr gut. Die Hervorsage ist ebenfalls ziemlich schlecht bzw. der Algorithmus. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4bf36",
   "metadata": {},
   "source": [
    "Mein Datensatz eigent sich nicht für die 7 Indikatoren und für das Wahrheitsmatrix. Dies liegt daran, dass ich eine Regression benutzt habe, welche nicht mit dem Classifier kompatibel ist. Für den Classifier braucht es genau zwei verschiedene Kategorien wie zum Beispiel 1 und 0 oder \"female\" und \"male\". Bei mir ist dies nicht der Fall. Ich habe 352 verschiedene Kategorien und deshalb ist es mit meinem Datensatz nicht möglich den FN, FP oder TP zu finden. Für diese benötigt man eben binäre Zahlen. Meine Daten auf und abzurunden lohnt sich ebenfalls nicht, da die Genauigkeit dann gleich Null ist und meine Daten dann keine Ausagekraft haben Aus diesem Grunde werde ich das ganze nicht mit meinem Datenset versuchen, sondern mit dem Datenset aus dem Auftrag 1760_xlsx. Das Datenset beinhaltet Angaben über das Gewicht die Grösse und das Geschlecht. Leider gibt es \"nur\" 500 Zeilen, jedoch wird es für den Sinn und Zweck der Aufgabe gut funktionieren.\n",
    "In diesem Beispiel habe ich den Decisiontree Classifier genommen, da diese die höchste Quote hatte. (Siehe unten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19629322",
   "metadata": {},
   "source": [
    "Frage: Ist die Person mit der Grösse X und dem Gewicht Y ein Mann oder eine Frau?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e94d395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "286b48ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>184</td>\n",
       "      <td>121</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>150</td>\n",
       "      <td>95</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>173</td>\n",
       "      <td>131</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Height  Weight     Sex\n",
       "0       174      96    Male\n",
       "1       189      87    Male\n",
       "2       185     110  Female\n",
       "3       195     104  Female\n",
       "4       149      61    Male\n",
       "..      ...     ...     ...\n",
       "495     150     153  Female\n",
       "496     184     121  Female\n",
       "497     141     136  Female\n",
       "498     150      95    Male\n",
       "499     173     131    Male\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('LA_1670_data.csv', sep=';')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e87cb",
   "metadata": {},
   "source": [
    "Nun habe ich den Male Werten die 1 gegeben und den Female Werten die 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bbeb9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      0\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "495    0\n",
       "496    0\n",
       "497    0\n",
       "498    1\n",
       "499    1\n",
       "Name: Sex, Length: 500, dtype: int32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sex'].replace('Female', 0 ,inplace=True)\n",
    "data['Sex'].replace('Male', 1,inplace=True)\n",
    "data['Sex'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dffa851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>184</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>141</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>150</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>173</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Height  Weight  Sex\n",
       "0       174      96    1\n",
       "1       189      87    1\n",
       "2       185     110    0\n",
       "3       195     104    0\n",
       "4       149      61    1\n",
       "..      ...     ...  ...\n",
       "495     150     153    0\n",
       "496     184     121    0\n",
       "497     141     136    0\n",
       "498     150      95    1\n",
       "499     173     131    1\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3fa2b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Height  Weight\n",
       "0     174      96\n",
       "1     189      87\n",
       "2     185     110\n",
       "3     195     104\n",
       "4     149      61"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[[\"Height\", \"Weight\"]]\n",
    "y = data[[\"Sex\"]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "061136ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scale = scaler.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f1f6cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree 0.54\n",
      "Random Forest 0.47\n",
      "Neural Net 0.44\n",
      "Naive Bayes 0.46\n",
      "LDA 0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "algorithms = {\n",
    "\n",
    "    \"Decision Tree\" : DecisionTreeClassifier(max_depth=20), \n",
    "    \"Random Forest\" : RandomForestClassifier(max_depth=45, n_estimators=30, max_features=1),\n",
    "    \"Neural Net\" : MLPClassifier(alpha=1, max_iter=10), \n",
    "    \"Naive Bayes\" : GaussianNB(), \n",
    "    \"LDA\" : LinearDiscriminantAnalysis(),\n",
    "}\n",
    "\n",
    "\n",
    "for name, algorithm in algorithms.items():\n",
    "\n",
    "    algorithm.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "    score = algorithm.score(X_test, y_test)\n",
    "    print(name, round(score,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdf5ce98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a logistic regression model on the training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# instantiate model\n",
    "logreg = DecisionTreeClassifier()\n",
    "\n",
    "# fit model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4c3f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for the testing set\n",
    "y_pred_class = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a14b13c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d26ee715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31 28]\n",
      " [29 37]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02fa6e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31 28]\n",
      " [29 37]]\n"
     ]
    }
   ],
   "source": [
    "# save confusion matrix and slice into four pieces\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_class)\n",
    "print(confusion)\n",
    "#[row, column]\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6324ad",
   "metadata": {},
   "source": [
    "## Messmetrik vom neuen Datenset (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6593b591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.456"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred_class)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417ca88d",
   "metadata": {},
   "source": [
    "## Indikatoren vom neuen Datenset + Auswahl (4.2/4.3)\n",
    "True Positive = 32\n",
    "\n",
    "False Positive = 29\n",
    "\n",
    "True Negative = 37\n",
    "\n",
    "False Negative = 27\n",
    "\n",
    "\n",
    "Ich werde die \"F1-Measure\" benutzen. Dies liegt daran, dass es bei dem recall eher um die Anzahl als um die Genauigkeit geht. Jedoch kann die Trefferquote auch sehr nützlich sein. Zudem ist es bei meiner Fragestellung ob es sich um einen Mann oder um eine Frau handelt auch wichtig, dass dass die Genauigkeit stimmt. Denn von meiner Seite aus wäre es nicht so super, wenn eine Frau ausversehen als Mann eingetragen wird. Jedoch finde ich dies nicht so schlimm, wie das Beispiel mit dem Gefängnis aus dem Auftrag 1670. Da eben beide (Recall und Precision) einen Sinn ergeben aber nicht die perfekte Lösung sind, habe ich mich dazu entschieden den F1-Measure zu nehmen. Dieser ist eben für solche Fälle da und ist die dritte Grösse, welche die beiden ersten Methoden kombiniert. F1-Measure kommt auch oft bei weniger extremen Fällen zum Vorschein.\n",
    "\n",
    "Villeicht fragen Sie sich jetzt: Weshalb habe ich nicht den precision genutzt, es wäre doch doof, wenn ein Mann plötzlich als Frau identifiziert wird. \n",
    "\n",
    "Antwort: Hier kann man bisschen die eigene Meinung einbauen. Da heutzutage sowieso schon alles gegendert wird, dachte ich dass es nicht so eine grosse Rolle spielt, ob jetzt di Genauigkeit hoch ist oder weniger hoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37aa37c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.564885496183206\n"
     ]
    }
   ],
   "source": [
    "# Messindiktor berechnen f1\n",
    "# Die Genauigkeit liegt bei 56 %, also rund jede zweite Ausgabe ist korrekt.\n",
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "print(2 * recall * precision / (recall + precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3f9bad",
   "metadata": {},
   "source": [
    "## Wahrheitsmatrix Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b938d2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    ">>> import matplotlib.pyplot as plt\n",
    ">>> from sklearn.datasets import make_classification\n",
    ">>> from sklearn.metrics import plot_confusion_matrix\n",
    ">>> from sklearn.model_selection import train_test_split\n",
    ">>> from sklearn.svm import SVC\n",
    ">>> X, y = make_classification(random_state=0)\n",
    ">>>\n",
    ">>> clf = SVC(random_state=0)\n",
    ">>> clf.fit(X_train, y_train)\n",
    "SVC(random_state=0)\n",
    ">>> plot_confusion_matrix(clf, X_test, y_test)  \n",
    ">>> plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb550981",
   "metadata": {},
   "source": [
    "## Aufgabe 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "422d5676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.544\n"
     ]
    }
   ],
   "source": [
    "# Wie viel mal ist der Classifier korrekt?\n",
    "((TP + TN) / float(TP + TN + FP + FN))\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42aeb7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45599999999999996\n"
     ]
    }
   ],
   "source": [
    "# Wie viel mal ist der Classifier inkorrekt?\n",
    "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
    "\n",
    "(classification_error)\n",
    "print(1 - metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af41dc89",
   "metadata": {},
   "source": [
    "### Sensitivität"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a58e61a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5606060606060606\n"
     ]
    }
   ],
   "source": [
    "# Wenn der aktuelle Wert positiv ist, wie viele Mal ist die Hervorsage korrekt? \n",
    "# Also wie empfindlich  ist der classifier beim entdecken von positiven Instanzen\n",
    "sensitivity = TP / float(FN + TP)\n",
    "\n",
    "(sensitivity)\n",
    "print(metrics.recall_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40548ae",
   "metadata": {},
   "source": [
    "### Spezifizität"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "354f4d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5254237288135594\n"
     ]
    }
   ],
   "source": [
    "# Wenn der aktuelle Wert negativ ist, wie oft ist die Hervorsage korrekt?\n",
    "# Wie spezifisch ist also der Classifier beim entdecken von positiven Instanzen\n",
    "specificity = TN / (TN + FP)\n",
    "\n",
    "print(specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8419c8",
   "metadata": {},
   "source": [
    "#### Fazit Spezifität und Sensivität: \n",
    "Die Hervorsage ist etwa gleich spezifisch wie empfindlich"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b83158a",
   "metadata": {},
   "source": [
    "## Aufgabe 4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15607c1c",
   "metadata": {},
   "source": [
    "Ich schreibe hier über das neue Datenset, also das Datenset wo 0 und 1 enthält."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e0832f",
   "metadata": {},
   "source": [
    "Das neue Modell funktioniert ziemlich gut. Wie man an dem MSE und F1-Measure sehen kann, stimmt ziemlich genau 50 Prozent der Hervorsagen. Dies liegt zum einen am Algorithmus-Classifier, da dieser sich für mein Modell ausgezeichnet lohnt und zum anderen hat die Grösse und das Alter mit dem Wert «Male» und «Female» einen grösseren Zusammenhang, als wenn man den Job noch einbauen würde. Dieses Datenset befindet sich fast überall im Durchschnitt. Das Gewicht und die Grösse spielen eine gleich grosse Rolle und sind auch sehr aussagekräftig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944eea7c",
   "metadata": {},
   "source": [
    "# LB-Fertig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
